services:
  spark-master:
    image: apache/spark:latest
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
    entrypoint: ["bash", "/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4050:4040"
    volumes:
      - ./data:/tmp/data/
      - ./output1/:/app/data/output/

  spark-worker-1:
    image: apache/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
    ports:
      - "8081:8081"
      - "4060:4040"
    entrypoint: ["bash", "/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    depends_on:
      - spark-master
    restart: always
    volumes:
      - ./data:/tmp/data/

  spark-worker-2:
    image: apache/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
    ports:
      - "8082:8081"
      - "4061:4040"
    entrypoint: [ "bash", "/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077" ]
    depends_on:
      - spark-master
    restart: always
    volumes:
      - ./data:/tmp/data/

  spark-job-submit:
    image: apache/spark:latest
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_DATA_PATH=/tmp/data/listings/
      - SPARK_OUTPUT_PATH=/app/output/extract
    entrypoint: ["bash", "/opt/spark/bin/spark-submit", "--py-files", "/app/jobs.zip,/app/config.zip", "/app/jobs/extract.py"]
    depends_on:
      - spark-master
    volumes:
      - ./jobs.zip:/app/jobs.zip
      - ./config.zip:/app/config.zip
      - ./jobs/:/app/jobs/
      - ./data:/tmp/data/